{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Argo / GO-SHIP Comparison\n",
    "\n",
    "This will serve as our working notebook, broken into our discussed working components below. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## This cell for imports, constants"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# data processing\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import xarray as xr\r\n",
    "from time import sleep\r\n",
    "\r\n",
    "# data visualization\r\n",
    "%matplotlib inline\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "# API convenience functions\r\n",
    "from utilities_NSF_EC2022 import get_data_for_timeRange\r\n",
    "\r\n",
    "# geographic functions\r\n",
    "import cartopy.crs as ccrs\r\n",
    "import cartopy.feature as cft\r\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "\r\n",
    "# set constants\r\n",
    "URL_PREFIX = 'https://argovis-api.colorado.edu'\r\n",
    "API_KEY = ''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## This cell for data loading/processing to xarray"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# more convenient wrapper for if you want a line just by name\n",
    "def get_goship_line(line_name, startDate='2000-01-01T00:00:00Z', endDate='2022-05-01T00:00:00Z', dt_tag='365d', url=URL_PREFIX, api_key=API_KEY):\n",
    "    df = get_data_for_timeRange(startDate, endDate, url_prefix=url+'/profiles?', \n",
    "                                source='cchdo_go-ship', woceline=line_name, \n",
    "                                myAPIkey=api_key, dt_tag=dt_tag)\n",
    "    return df\n",
    "\n",
    "# I think we should have a time independent version of this function as well\n",
    "# could cheat this function into doing it with something like timedelta=1e5 or something\n",
    "def get_argo_along_line(time, coords, radius=50, timedelta=30, dt_tag='365d', url=URL_PREFIX, api_key=API_KEY):\n",
    "    df_all = pd.DataFrame()\n",
    "    for t, c in zip(time, coords):\n",
    "        sleep(.2)\n",
    "        startDate = (pd.Timestamp(t) - pd.Timedelta(timedelta/2)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        endDate   = (pd.Timestamp(t) + pd.Timedelta(timedelta/2)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        center    = f'{c[0]},{c[1]}'\n",
    "        df = get_data_for_timeRange(startDate, endDate, url_prefix=url+'/profiles?',\n",
    "            center=center, radius_km=f'{radius}', source='argo_core', data='pres,temp,psal',\n",
    "            myAPIkey=api_key, dt_tag=dt_tag, writeFlag=False)\n",
    "        df_all = df_all.append(df)\n",
    "    \n",
    "    return df_all\n",
    "\n",
    "# get argo data along line A22\n",
    "a22 = get_goship_line('A22')\n",
    "coords = [c['coordinates'] for c in a22.geolocation]\n",
    "time = a22.timestamp.values\n",
    "argo_a22 = get_argo_along_line(time, coords)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "argo_a22"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# process data from full of JSON points to more usable form\r\n",
    "def json_dataframe_to_dataframe(df):\r\n",
    "    out = pd.DataFrame()\r\n",
    "    for i in range(df.shape[0]):\r\n",
    "        # get the argo data\r\n",
    "        data_dict = dict()\r\n",
    "        data = df.data.iloc[i]\r\n",
    "        # repeat location and time data for same lenth as array\r\n",
    "        N_levels = len(data)\r\n",
    "        data_dict['wmo'] = N_levels*[int(df._id.iloc[i].split('_')[0])]\r\n",
    "        data_dict['cycle_number'] = N_levels*[df.cycle_number.iloc[i]]\r\n",
    "        data_dict['time'] = N_levels*[df.timestamp.iloc[i]]\r\n",
    "        data_dict['longitude'] = N_levels*[df.geolocation.iloc[i]['coordinates'][0]]\r\n",
    "        data_dict['latitude'] = N_levels*[df.geolocation.iloc[i]['coordinates'][1]]\r\n",
    "        # extract data from JSON dict\r\n",
    "        for k in df.data_keys.iloc[i]:\r\n",
    "            data_dict[k] = [d[k] for d in data]\r\n",
    "\r\n",
    "        out = pd.concat((out, pd.DataFrame(data_dict, index=(i+1)*np.ones((N_levels,), dtype=int))))\r\n",
    "    \r\n",
    "    return out\r\n",
    "\r\n",
    "df = json_dataframe_to_dataframe(argo_a22)\r\n",
    "\r\n",
    "def dataframe_to_xarray(df):\r\n",
    "    # get max number of depth levels\r\n",
    "    ix = df.index.unique()\r\n",
    "    number_profiles = ix.shape[0]\r\n",
    "    max_levels = -np.inf\r\n",
    "    for nprof in ix:\r\n",
    "        if df.loc[nprof].shape[0] > max_levels:\r\n",
    "            max_levels = df.loc[nprof].shape[0]\r\n",
    "\r\n",
    "    # extract lower dimension metadata\r\n",
    "    metadata = ['wmo', 'cycle_number', 'time', 'longitude', 'latitude']\r\n",
    "    meta_dict = dict()\r\n",
    "    for k in metadata:\r\n",
    "        meta_dict[k] = [df[k].loc[i].iloc[0] for i in ix]\r\n",
    "    df = df.drop(metadata, axis=1)\r\n",
    "    data_dict = {k:np.nan*np.ones((number_profiles, max_levels)) for k in df.columns}\r\n",
    "\r\n",
    "    # put argo data into \"square\" arrays\r\n",
    "    for nprof in ix:\r\n",
    "        profile = df.loc[nprof]\r\n",
    "        current_depth_levels = profile.shape[0]\r\n",
    "        for k in profile.columns:\r\n",
    "            data_dict[k][nprof-1,:current_depth_levels] = profile[k]\r\n",
    "    \r\n",
    "\r\n",
    "    # create xarray dataset\r\n",
    "    ds = xr.Dataset(\r\n",
    "        data_vars = {k:(['n_prof', 'n_level'], v) for k, v in data_dict.items()},\r\n",
    "        coords = {k:(['n_prof'], v) for k, v in meta_dict.items()}\r\n",
    "    )\r\n",
    "    # transpose for simpler plotting\r\n",
    "    ds = ds.transpose('n_level', 'n_prof')\r\n",
    "\r\n",
    "    return ds\r\n",
    "\r\n",
    "ds = dataframe_to_xarray(df)\r\n",
    "ds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## This cell for Data Visualization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# mapping function\r\n",
    "def create_map(coords, line_name):\r\n",
    "    # figure out appropriate extent\r\n",
    "    coords = np.array(coords)\r\n",
    "    line_limits = [\r\n",
    "        [np.min(coords[:,0]), np.max(coords[:,0])],\r\n",
    "        [np.min(coords[:,1]), np.max(coords[:,1])]\r\n",
    "    ]\r\n",
    "\r\n",
    "    # set up map\r\n",
    "    fig = plt.figure()\r\n",
    "    projection = ccrs.PlateCarree()\r\n",
    "    transform = ccrs.PlateCarree()\r\n",
    "    ax = fig.add_subplot(projection=projection)\r\n",
    "    ax.set_extent([line_limits[0][0]-5, line_limits[0][1]+5, line_limits[1][0]-2, line_limits[1][1]+2])\r\n",
    "    ax.add_feature(cft.GSHHSFeature('intermediate', edgecolor='black'))\r\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=True)\r\n",
    "    lat_formatter = LatitudeFormatter()\r\n",
    "    gl = ax.gridlines(crs=transform, draw_labels=True)\r\n",
    "    gl.right_labels = False\r\n",
    "    gl.xformatter = lon_formatter\r\n",
    "    gl.yformatter = lat_formatter\r\n",
    "\r\n",
    "    # plot go-ship line coordinates\r\n",
    "    ax.plot(coords[:,0], coords[:,1], 'ko', transform=transform, label=line_name)\r\n",
    "    # plot Argo coordinates\r\n",
    "    ax.plot(ds.longitude, ds.latitude, 'o', color='red', transform=transform, label='Core Argo Profiles')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Draw map with function\n",
    "create_map(coords, \"GO-SHIP Line A22\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Wrapping everything up into one function\r\n",
    "def argo_and_goship(goship_line_name, show_map = True, startDate='2000-01-01T00:00:00Z', endDate='2022-05-01T00:00:00Z', dt_tag='365d', radius=50, timedelta=30, url=URL_PREFIX, api_key=API_KEY):\r\n",
    "    try:\r\n",
    "        goship_line = get_goship_line(goship_line_name)\r\n",
    "        coords = [c['coordinates'] for c in goship_line.geolocation]\r\n",
    "        time = goship_line.timestamp.values\r\n",
    "        argo = get_argo_along_line(time, coords)\r\n",
    "        \r\n",
    "        df = json_dataframe_to_dataframe(argo)\r\n",
    "        ds = dataframe_to_xarray(df)\r\n",
    "        \r\n",
    "        if show_map == True:\r\n",
    "            create_map(coords, goship_line_name)\r\n",
    "    \r\n",
    "    except:\r\n",
    "        print(\"Invalid line. Please try again.\")\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "argo_and_goship('P16')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## This cell for Data Interpolation/Comparison"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def interp_xarray(ds, pressure_range):\r\n",
    "    meta_dict = {k:ds[k].data for k in ds.coords}\r\n",
    "    interp_dict = {k:np.nan*np.ones((ds.dims['n_prof'], pressure_range.shape[0])) for k in ds.keys() if k != 'pres'}\r\n",
    "    for i in ds.keys():\r\n",
    "        if i!= 'pres':\r\n",
    "            for j in range(ds.dims['n_prof']):\r\n",
    "                interp_dict[i][j,:] = np.interp(pressure_range, ds.pres[:,j], ds[i][:,j])\r\n",
    "\r\n",
    "    # create xarray dataset\r\n",
    "    coords_dict = {k:(['n_prof'], v) for k,v in meta_dict.items()}\r\n",
    "    coords_dict['pres'] = (['n_level'], pressure_range)\r\n",
    "\r\n",
    "    ds = xr.Dataset(\r\n",
    "        data_vars = {k:(['n_prof', 'n_level'], v) for k,v in interp_dict.items()},\r\n",
    "        coords =  coords_dict\r\n",
    "    )\r\n",
    "\r\n",
    "    # transpose dims for easier plotting\r\n",
    "    ds = ds.transpose('n_level','n_prof')\r\n",
    "\r\n",
    "    return ds\r\n",
    "\r\n",
    "ids = interp_xarray(ds, np.arange(0, 2020, 20))\r\n",
    "ids"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "468ecce84b050c0641df651fd4dc0aab60643e0baf69ec668fbaa0a2423138fd"
  },
  "kernelspec": {
   "display_name": "Python(argovis)",
   "language": "python",
   "name": "argovis_demos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}