{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Argo and GO-SHIP data\n",
    "\n",
    "In this Example notebook, profile data from a selected GO-SHIP cruise line is obtained, along with nearby Argo profiles that fall within user-provided time and space constraints from the GO-SHIP profiles. Those profile data are converted to more user-friendly xarray format, plotted as profiles and sections, interpolated onto a regular grid for comparison, and plotted as differences on that regular grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0: Import necessary packages and set constants for upcoming functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import xarray as xr\r\n",
    "from time import sleep\r\n",
    "\r\n",
    "# data visualization\r\n",
    "%matplotlib inline\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "# API convenience functions\r\n",
    "from utilities_NSF_EC2022 import get_data_for_timeRange\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "\r\n",
    "# set constants\r\n",
    "URL_PREFIX = 'https://argovis-api.colorado.edu'\r\n",
    "API_KEY = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Download data from GO-SHIP line\n",
    "With the function *get_goship_line*, users can provide the name of a GO-SHIP to download all historical profiles from that line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function\n",
    "def get_goship_line(line_name, startDate='1900-01-01T00:00:00Z', endDate='2022-05-01T00:00:00Z', dt_tag='365d', url=URL_PREFIX, api_key=API_KEY):\n",
    "    df = get_data_for_timeRange(startDate, endDate, url_prefix=url+'/profiles?', \n",
    "                                source='cchdo_go-ship', woceline=line_name, \n",
    "                                myAPIkey=api_key, dt_tag=dt_tag)\n",
    "    return df\n",
    "\n",
    "# get GO-SHIP data from line A22\n",
    "a22 = get_goship_line('A22')\n",
    "coords = [c['coordinates'] for c in a22.geolocation]\n",
    "time = a22.timestamp.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Download data from surrounding Argo profiles\n",
    "With the function *get_argo_along_line*, users can download data from Argo profiles that are within given time and space constraints from a given set of profiles (in this case the GO-SHIP data we downloaded in Task 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# define the function\n",
    "# I think we should have a time independent version of this function as well\n",
    "# could cheat this function into doing it with something like timedelta=1e5 or something\n",
    "def get_argo_along_line(time, coords, radius=50, timedelta=30, dt_tag='365d', url=URL_PREFIX, api_key=API_KEY):\n",
    "    df_all = pd.DataFrame()\n",
    "    for t, c in zip(time, coords):\n",
    "        sleep(.2)\n",
    "        startDate = (pd.Timestamp(t) - pd.Timedelta(timedelta/2)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        endDate   = (pd.Timestamp(t) + pd.Timedelta(timedelta/2)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        center    = f'{c[0]},{c[1]}'\n",
    "        df = get_data_for_timeRange(startDate, endDate, url_prefix=url+'/profiles?',\n",
    "            center=center, radius_km=f'{radius}', source='argo_core', data='pres,temp,psal',\n",
    "            myAPIkey=api_key, dt_tag=dt_tag, writeFlag=False)\n",
    "        df_all = df_all.append(df)\n",
    "    \n",
    "    return df_all\n",
    "\n",
    "# get argo data along line A22\n",
    "argo_a22 = get_argo_along_line(time, coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Convert data to xarray\n",
    "The function *json_dataframe_to_dataframe* processes the data downloaded from prior tasks in json format to be ready for conversion to an xarray. The function *to_xarray* converts the data to an xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# process data from full of JSON points to more usable form\r\n",
    "def json_dataframe_to_dataframe(df):\r\n",
    "    out = pd.DataFrame()\r\n",
    "    for i in range(df.shape[0]):\r\n",
    "        # get the argo data\r\n",
    "        data_dict = dict()\r\n",
    "        data = df.data.iloc[i]\r\n",
    "        # repeat location and time data for same lenth as array\r\n",
    "        N_levels = len(data)\r\n",
    "        data_dict['wmo'] = N_levels*[int(df._id.iloc[i].split('_')[0])]\r\n",
    "        data_dict['cycle_number'] = N_levels*[df.cycle_number.iloc[i]]\r\n",
    "        data_dict['time'] = N_levels*[df.timestamp.iloc[i]]\r\n",
    "        data_dict['longitude'] = N_levels*[df.geolocation.iloc[i]['coordinates'][0]]\r\n",
    "        data_dict['latitude'] = N_levels*[df.geolocation.iloc[i]['coordinates'][1]]\r\n",
    "        # extract data from JSON dict\r\n",
    "        for k in df.data_keys.iloc[i]:\r\n",
    "            data_dict[k] = [d[k] for d in data]\r\n",
    "\r\n",
    "        out = pd.concat((out, pd.DataFrame(data_dict, index=(i+1)*np.ones((N_levels,), dtype=int))))\r\n",
    "    \r\n",
    "    return out\r\n",
    "\r\n",
    "df = json_dataframe_to_dataframe(argo_a22)\r\n",
    "\r\n",
    "def dataframe_to_xarray(df):\r\n",
    "    # get max number of depth levels\r\n",
    "    ix = df.index.unique()\r\n",
    "    number_profiles = ix.shape[0]\r\n",
    "    max_levels = -np.inf\r\n",
    "    for nprof in ix:\r\n",
    "        if df.loc[nprof].shape[0] > max_levels:\r\n",
    "            max_levels = df.loc[nprof].shape[0]\r\n",
    "\r\n",
    "    # extract lower dimension metadata\r\n",
    "    metadata = ['wmo', 'cycle_number', 'time', 'longitude', 'latitude']\r\n",
    "    meta_dict = dict()\r\n",
    "    for k in metadata:\r\n",
    "        meta_dict[k] = [df[k].loc[i].iloc[0] for i in ix]\r\n",
    "    df = df.drop(metadata, axis=1)\r\n",
    "    data_dict = {k:np.nan*np.ones((number_profiles, max_levels)) for k in df.columns}\r\n",
    "\r\n",
    "    # put argo data into \"square\" arrays\r\n",
    "    for nprof in ix:\r\n",
    "        profile = df.loc[nprof]\r\n",
    "        current_depth_levels = profile.shape[0]\r\n",
    "        for k in profile.columns:\r\n",
    "            data_dict[k][nprof-1,:current_depth_levels] = profile[k]\r\n",
    "    \r\n",
    "\r\n",
    "    # create xarray dataset\r\n",
    "    ds = xr.Dataset(\r\n",
    "        data_vars = {k:(['n_prof', 'n_level'], v) for k, v in data_dict.items()},\r\n",
    "        coords = {k:(['n_prof'], v) for k, v in meta_dict.items()}\r\n",
    "    )\r\n",
    "    # transpose for simpler plotting\r\n",
    "    ds = ds.transpose('n_level', 'n_prof')\r\n",
    "\r\n",
    "    return ds\r\n",
    "\r\n",
    "ds = dataframe_to_xarray(df)"
   ],
   "outputs": [],
   "source": [
    "# process data from full of JSON points to more usable form\n",
    "def json_dataframe_to_dataframe(df):\n",
    "    out = pd.DataFrame()\n",
    "    for i in range(df.shape[0]):\n",
    "        # get the argo data\n",
    "        data_dict = dict()\n",
    "        data = df.data.iloc[i]\n",
    "        # repeat location and time data for same lenth as array\n",
    "        N_levels = len(data)\n",
    "        data_dict['wmo'] = N_levels*[int(df._id.iloc[i].split('_')[0])]\n",
    "        data_dict['cycle_number'] = N_levels*[df.cycle_number.iloc[i]]\n",
    "        data_dict['time'] = N_levels*[df.timestamp.iloc[i]]\n",
    "        data_dict['longitude'] = N_levels*[df.geolocation.iloc[i]['coordinates'][0]]\n",
    "        data_dict['latitude'] = N_levels*[df.geolocation.iloc[i]['coordinates'][1]]\n",
    "        # extract data from JSON dict\n",
    "        for k in df.data_keys.iloc[i]:\n",
    "            data_dict[k] = [d[k] for d in data]\n",
    "\n",
    "        out = out.append(pd.DataFrame(data_dict))\n",
    "    \n",
    "    return out\n",
    "\n",
    "df = json_dataframe_to_dataframe(argo_a22)\n",
    "ds = df.to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Plot GO-SHIP and Argo data\n",
    "First, we’ll plot data from each source as individual profiles(?), then as sections across latitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Interpolate data to regular depth levels\n",
    "To compare GO-SHIP data with nearby Argo profiles, we’ll need the data to be on consistent depth levels. With the function *function name*, we can interpolate profiles onto a regular 2-dbar(?) by 0.1 degree(?) grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "display_name": "argovis_demos",
   "language": "python",
   "name": "argovis_demos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
